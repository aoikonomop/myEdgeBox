{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from scipy.io import loadmat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1) Read data\n",
    "Read the matlab generated `mat` file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'data_alpha0.65_beta0.75_r1_conf_th0.01_edge_size200.mat'\n",
    "image_shape = [1080, 1920]\n",
    "iou_threshold = 0.5\n",
    "data_dict = loadmat(path)['data']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) Populate\n",
    "Populate a list with all the entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_boxes = []\n",
    "predicted_boxes = []\n",
    "proj_matrices = []\n",
    "\n",
    "max_gt = 0\n",
    "max_predicted = 0\n",
    "\n",
    "for i in range(data_dict.shape[0]):\n",
    "    gt_boxes.append(data_dict[i][0][1])\n",
    "    predicted_boxes.append(data_dict[i][0][2][:, :4])\n",
    "    proj_matrices.append(data_dict[i][0][3])\n",
    "    \n",
    "    if max_gt < gt_boxes[-1].shape[0]:\n",
    "        max_gt = gt_boxes[-1].shape[0]\n",
    "        \n",
    "    if max_predicted < predicted_boxes[-1].shape[0]:\n",
    "        max_predicted = predicted_boxes[-1].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3) Pad\n",
    "Fill out a matrix with the predicted boxes and ground truth appended with -1s according to their maximum sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_boxes_padded = []\n",
    "for i in range(len(predicted_boxes)):\n",
    "    temp_boxes = predicted_boxes[i]\n",
    "    padded = - np.ones((max_predicted, 4))\n",
    "    if predicted_boxes[i].shape[0]:\n",
    "        padded[:temp_boxes.shape[0], :] = temp_boxes\n",
    "    predicted_boxes_padded.append(padded)\n",
    "predicted_boxes = predicted_boxes_padded\n",
    "\n",
    "gt_boxes_padded = []\n",
    "for i in range(len(gt_boxes)):\n",
    "    temp_boxes = gt_boxes[i]\n",
    "    padded = - np.ones((max_gt, 4))\n",
    "    if gt_boxes[i].shape[0] > 0:\n",
    "        padded[:temp_boxes.shape[0], :] = temp_boxes\n",
    "    gt_boxes_padded.append(padded)\n",
    "gt_boxes = gt_boxes_padded\n",
    "\n",
    "predicted_boxes = np.stack(predicted_boxes)\n",
    "gt_boxes = np.stack(gt_boxes)\n",
    "proj_matrices = np.stack(proj_matrices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4) Tensors!\n",
    "Set the tensors in prepearation of the evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_tensor = tf.constant(predicted_boxes, dtype=tf.float32)\n",
    "gt_tensor = dict(boxes=tf.constant(gt_boxes, dtype=tf.float32), proj_matrix=tf.constant(proj_matrices, dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5a) Apply `DetectionEvaluator` from beatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hudl_beatrix.evaluators import ModModelEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = ModModelEvaluator(iou_threshold=iou_threshold)\n",
    "log_results_tensor = evaluator(gt_tensor, predicted_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with tf.Session() as s:\n",
    "    stats = s.run(log_results_tensor)\n",
    "\n",
    "print(stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5b) Apply `WatsonFilteringEvaluator` from beatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hudl_beatrix.evaluators.model_wrappers.watson_filtering import WatsonFilteringModelEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "evaluator = WatsonFilteringModelEvaluator(iou_threshold=iou_threshold)\n",
    "stats_tensor = evaluator(gt_tensor, predicted_tensor, \n",
    "                         input_height=image_shape[0],\n",
    "                         input_width=image_shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as s:\n",
    "    stats = s.run(stats_tensor)\n",
    "\n",
    "print(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
